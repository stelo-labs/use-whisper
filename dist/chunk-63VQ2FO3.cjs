'use strict';

var chunk57AVKP4H_cjs = require('./chunk-57AVKP4H.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');
var recordrtc = require('recordrtc');
var lamejs = require('lamejs');
var ie = require('hark');
var ffmpeg = require('@ffmpeg/ffmpeg');
var ce = require('axios');

function _interopDefault (e) { return e && e.__esModule ? e : { default: e }; }

var ie__default = /*#__PURE__*/_interopDefault(ie);
var ce__default = /*#__PURE__*/_interopDefault(ce);

var ue={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0},pe={stop:void 0},fe={blob:void 0,text:void 0},Se=P=>{let{apiKey:m,autoStart:v,autoTranscribe:A,mode:y,nonStop:C,removeSilence:L,stopTimeout:M,streaming:h,timeSlice:q,whisperConfig:c,onDataAvailable:I,onTranscribe:S}={...ue,...P};if(!m&&!S)throw new Error("apiKey is required if onTranscribe is not provided");let f=react.useRef([]),a=react.useRef(),i=react.useRef(),r=react.useRef(),o=react.useRef(),d=react.useRef(pe),[K,T]=react.useState(!1),[O,U]=react.useState(!1),[$,g]=react.useState(!1),[j,l]=react.useState(fe);react.useEffect(()=>()=>{f.current&&(f.current=[]),a.current&&(a.current.flush(),a.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),b("stop"),i.current&&(i.current.off("speaking",k),i.current.off("stopped_speaking",R)),o.current&&(o.current.getTracks().forEach(e=>e.stop()),o.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{v&&await B();},[v]);let z=async()=>{await B();},N=async()=>{await Q();},G=async()=>{await x();},B=async()=>{try{if(o.current||await J(),o.current){if(!r.current){let t={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:recordrtc.StereoAudioRecorder,sampleRate:44100,timeSlice:h?q:void 0,type:"audio",ondataavailable:A&&h?Y:void 0};r.current=new recordrtc.RecordRTCPromisesHandler(o.current,t);}a.current||(a.current=new lamejs.Mp3Encoder(1,44100,96));let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),C&&W("stop"),T(!0);}}catch{}},J=async()=>{try{o.current&&o.current.getTracks().forEach(e=>e.stop()),o.current=await navigator.mediaDevices.getUserMedia({audio:!0}),i.current||(i.current=ie__default.default(o.current,{interval:100,play:!1}),i.current.on("speaking",k),i.current.on("stopped_speaking",R));}catch{}},W=e=>{d.current[e]||(d.current[e]=setTimeout(x,M));},k=()=>{U(!0),b("stop");},R=()=>{U(!1),C&&W("stop");},Q=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),b("stop"),T(!1));}catch{}},x=async()=>{try{if(r.current){let e=await r.current.getState();if((e==="recording"||e==="paused")&&await r.current.stopRecording(),V(),b("stop"),T(!1),A)await X();else {let t=await r.current.getBlob();l({blob:t});}await r.current.destroy(),f.current=[],a.current&&(a.current.flush(),a.current=void 0),r.current=void 0;}}catch{}},V=()=>{i.current&&(i.current.off("speaking",k),i.current.off("stopped_speaking",R),i.current=void 0),o.current&&(o.current.getTracks().forEach(e=>e.stop()),o.current=void 0);},b=e=>{d.current[e]&&(clearTimeout(d.current[e]),d.current[e]=void 0);},X=async()=>{try{if(a.current&&r.current&&await r.current.getState()==="stopped"){g(!0);let t=await r.current.getBlob();if(L){let n=ffmpeg.createFFmpeg({mainName:"main",corePath:chunk57AVKP4H_cjs.b,log:!0});n.isLoaded()||await n.load();let s=await t.arrayBuffer();n.FS("writeFile","in.wav",new Uint8Array(s)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",chunk57AVKP4H_cjs.c,"out.mp3");let u=n.FS("readFile","out.mp3");if(u.length<=225){n.exit(),l({blob:t}),g(!1);return}t=new Blob([u.buffer],{type:"audio/mpeg"}),n.exit();}else {let n=await t.arrayBuffer(),s=a.current.encodeBuffer(new Int16Array(n));t=new Blob([s],{type:"audio/mpeg"});}if(typeof S=="function"){let n=await S(t);l(n);}else {let n=new File([t],"speech.mp3",{type:"audio/mpeg"}),s=await E(n);l({blob:t,text:s});}g(!1);}}catch{g(!1);}},Y=async e=>{try{if(h&&r.current){if(I?.(e),a.current){let n=await e.arrayBuffer(),s=a.current.encodeBuffer(new Int16Array(n)),u=new Blob([s],{type:"audio/mpeg"});f.current.push(u);}if(await r.current.getState()==="recording"){let n=new Blob(f.current,{type:"audio/mpeg"}),s=new File([n],"speech.mp3",{type:"audio/mpeg"}),u=await E(s);u&&l(Z=>({...Z,text:u}));}}}catch{}},E=reactHooksAsync.useMemoAsync(async e=>{let t=new FormData;t.append("file",e),t.append("model","whisper-1"),y==="transcriptions"&&t.append("language",c?.language??"en"),c?.prompt&&t.append("prompt",c.prompt),c?.response_format&&t.append("response_format",c.response_format),c?.temperature&&t.append("temperature",`${c.temperature}`);let n={};return n["Content-Type"]="multipart/form-data",m&&(n.Authorization=`Bearer ${m}`),(await ce__default.default.post(chunk57AVKP4H_cjs.d+y,t,{headers:n})).data.text},[m,y,c]);return {recording:K,speaking:O,transcribing:$,transcript:j,pauseRecording:N,startRecording:z,stopRecording:G}};

exports.a = Se;
